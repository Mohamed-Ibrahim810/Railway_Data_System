{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the source data from the Bronze layer in the data warehouse\n",
    "\n",
    "server = 'mohamedibrahim'\n",
    "database = 'railway_dwh'\n",
    "\n",
    "connection_string = (\n",
    "    f'mssql+pyodbc://mohamedibrahim/railway_dwh'\n",
    "    '?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    '&Trusted_Connection=yes'\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = \"SELECT * FROM bronze.railway\"\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TransactionID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date_of_Purchase",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Time_of_Purchase",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Purchase_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Payment_Method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Railcard",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ticket_Class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ticket_Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Departure_Station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Arrival_Station",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date_of_Journey",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Departure_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Arrival_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Actual_Arrival_Time",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Journey_Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Reason_for_Delay",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Refund_Request",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e5908b04-3746-4b76-96cf-0f68beda6b76",
       "rows": [
        [
         "0",
         "da8a6ba8-b3dc-4677-b176",
         "2023-12-08",
         "12:41:11",
         "Online",
         "Contactless",
         "Adult",
         "Standard",
         "Advance",
         "43",
         "London Paddington",
         "Liverpool Lime Street",
         "2024-01-01",
         "11:00:00",
         "13:30:00",
         "13:30:00",
         "On Time",
         null,
         "No"
        ],
        [
         "1",
         "b0cdd1b0-f214-4197-be53",
         "2023-12-16",
         "11:23:01",
         "Station",
         "Credit Card",
         "Adult",
         "Standard",
         "Advance",
         "23",
         "London Kings Cross",
         "York",
         "2024-01-01",
         "09:45:00",
         "11:35:00",
         "11:40:00",
         "Delayed",
         "Signal Failure",
         "No"
        ],
        [
         "2",
         "f3ba7a96-f713-40d9-9629",
         "2023-12-19",
         "19:51:27",
         "Online",
         "Credit Card",
         "None",
         "Standard",
         "Advance",
         "3",
         "Liverpool Lime Street",
         "Manchester Piccadilly",
         "2024-01-02",
         "18:15:00",
         "18:45:00",
         "18:45:00",
         "On Time",
         null,
         "No"
        ],
        [
         "3",
         "b2471f11-4fe7-4c87-8ab4",
         "2023-12-20",
         "23:00:36",
         "Station",
         "Credit Card",
         "None",
         "Standard",
         "Advance",
         "13",
         "London Paddington",
         "Reading",
         "2024-01-01",
         "21:30:00",
         "22:30:00",
         "22:30:00",
         "On Time",
         null,
         "No"
        ],
        [
         "4",
         "2be00b45-0762-485e-a7a3",
         "2023-12-27",
         "18:22:56",
         "Online",
         "Contactless",
         "None",
         "Standard",
         "Advance",
         "76",
         "Liverpool Lime Street",
         "London Euston",
         "2024-01-01",
         "16:45:00",
         "19:00:00",
         "19:00:00",
         "On Time",
         null,
         "No"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date_of_Purchase</th>\n",
       "      <th>Time_of_Purchase</th>\n",
       "      <th>Purchase_Type</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Railcard</th>\n",
       "      <th>Ticket_Class</th>\n",
       "      <th>Ticket_Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Departure_Station</th>\n",
       "      <th>Arrival_Station</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Departure_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Actual_Arrival_Time</th>\n",
       "      <th>Journey_Status</th>\n",
       "      <th>Reason_for_Delay</th>\n",
       "      <th>Refund_Request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da8a6ba8-b3dc-4677-b176</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>12:41:11</td>\n",
       "      <td>Online</td>\n",
       "      <td>Contactless</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>43</td>\n",
       "      <td>London Paddington</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0cdd1b0-f214-4197-be53</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>11:23:01</td>\n",
       "      <td>Station</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>23</td>\n",
       "      <td>London Kings Cross</td>\n",
       "      <td>York</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>09:45:00</td>\n",
       "      <td>11:35:00</td>\n",
       "      <td>11:40:00</td>\n",
       "      <td>Delayed</td>\n",
       "      <td>Signal Failure</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f3ba7a96-f713-40d9-9629</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>19:51:27</td>\n",
       "      <td>Online</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>3</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>18:15:00</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2471f11-4fe7-4c87-8ab4</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>23:00:36</td>\n",
       "      <td>Station</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>13</td>\n",
       "      <td>London Paddington</td>\n",
       "      <td>Reading</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2be00b45-0762-485e-a7a3</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>18:22:56</td>\n",
       "      <td>Online</td>\n",
       "      <td>Contactless</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>76</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>London Euston</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>16:45:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TransactionID Date_of_Purchase Time_of_Purchase Purchase_Type  \\\n",
       "0  da8a6ba8-b3dc-4677-b176       2023-12-08         12:41:11        Online   \n",
       "1  b0cdd1b0-f214-4197-be53       2023-12-16         11:23:01       Station   \n",
       "2  f3ba7a96-f713-40d9-9629       2023-12-19         19:51:27        Online   \n",
       "3  b2471f11-4fe7-4c87-8ab4       2023-12-20         23:00:36       Station   \n",
       "4  2be00b45-0762-485e-a7a3       2023-12-27         18:22:56        Online   \n",
       "\n",
       "  Payment_Method Railcard Ticket_Class Ticket_Type  Price  \\\n",
       "0    Contactless    Adult     Standard     Advance     43   \n",
       "1    Credit Card    Adult     Standard     Advance     23   \n",
       "2    Credit Card     None     Standard     Advance      3   \n",
       "3    Credit Card     None     Standard     Advance     13   \n",
       "4    Contactless     None     Standard     Advance     76   \n",
       "\n",
       "       Departure_Station        Arrival_Station Date_of_Journey  \\\n",
       "0      London Paddington  Liverpool Lime Street      2024-01-01   \n",
       "1     London Kings Cross                   York      2024-01-01   \n",
       "2  Liverpool Lime Street  Manchester Piccadilly      2024-01-02   \n",
       "3      London Paddington                Reading      2024-01-01   \n",
       "4  Liverpool Lime Street          London Euston      2024-01-01   \n",
       "\n",
       "  Departure_Time Arrival_Time Actual_Arrival_Time Journey_Status  \\\n",
       "0       11:00:00     13:30:00            13:30:00        On Time   \n",
       "1       09:45:00     11:35:00            11:40:00        Delayed   \n",
       "2       18:15:00     18:45:00            18:45:00        On Time   \n",
       "3       21:30:00     22:30:00            22:30:00        On Time   \n",
       "4       16:45:00     19:00:00            19:00:00        On Time   \n",
       "\n",
       "  Reason_for_Delay Refund_Request  \n",
       "0             None             No  \n",
       "1   Signal Failure             No  \n",
       "2             None             No  \n",
       "3             None             No  \n",
       "4             None             No  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31653 entries, 0 to 31652\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   TransactionID        31653 non-null  object\n",
      " 1   Date_of_Purchase     31653 non-null  object\n",
      " 2   Time_of_Purchase     31653 non-null  object\n",
      " 3   Purchase_Type        31653 non-null  object\n",
      " 4   Payment_Method       31653 non-null  object\n",
      " 5   Railcard             31653 non-null  object\n",
      " 6   Ticket_Class         31653 non-null  object\n",
      " 7   Ticket_Type          31653 non-null  object\n",
      " 8   Price                31653 non-null  int64 \n",
      " 9   Departure_Station    31653 non-null  object\n",
      " 10  Arrival_Station      31653 non-null  object\n",
      " 11  Date_of_Journey      31653 non-null  object\n",
      " 12  Departure_Time       31653 non-null  object\n",
      " 13  Arrival_Time         31653 non-null  object\n",
      " 14  Actual_Arrival_Time  29773 non-null  object\n",
      " 15  Journey_Status       31653 non-null  object\n",
      " 16  Reason_for_Delay     4172 non-null   object\n",
      " 17  Refund_Request       31653 non-null  object\n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id            0\n",
       "date_of_purchase          0\n",
       "time_of_purchase          0\n",
       "purchase_type             0\n",
       "payment_method            0\n",
       "railcard                  0\n",
       "ticket_class              0\n",
       "ticket_type               0\n",
       "price                     0\n",
       "departure_station         0\n",
       "arrival_station           0\n",
       "date_of_journey           0\n",
       "departure_time            0\n",
       "arrival_time              0\n",
       "actual_arrival_time    1880\n",
       "journey_status            0\n",
       "reason_for_delay          0\n",
       "refund_request            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n"
     ]
    }
   ],
   "source": [
    "# Checks each object column for unwanted spaces (leading spaces, trailing spaces, multiple spaces)\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    has_unwanted_spaces = False\n",
    "    \n",
    "    # Iterate through non-null values and check each one\n",
    "    for value in df[col][df[col].notna()]:\n",
    "        # Convert to string and check for unwanted spaces\n",
    "        str_value = str(value)\n",
    "        # Check for leading/trailing spaces or multiple consecutive spaces\n",
    "        if str_value != str_value.strip() or '  ' in str_value:\n",
    "            has_unwanted_spaces = True\n",
    "            break\n",
    "    \n",
    "    if has_unwanted_spaces:\n",
    "        print(f\"Unwanted spaces found in column: {col}\")\n",
    "\n",
    "    else:\n",
    "        print(\"It's all good :)\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section outlines the naming conventions used for tables, columns and other objects in the data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Conventions: Use snake_case, with lowercase letters and underscores (_) to separate words, this applies to any tables, columns and objects exepect columns values, stays as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'transactionid': 'transaction_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"transaction_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transaction_id'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"date_of_purchase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: date_of_purchase, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Date_of_Purchase\n",
    "# Using pattern matching to detect anomalies\n",
    "import re\n",
    "\n",
    "pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "anomalies = df.loc[~df['date_of_purchase'].astype(str).str.match(pattern), 'date_of_purchase']\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"time_of_purchase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: time_of_purchase, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^\\d{2}:\\d{2}:\\d{2}$'\n",
    "anomalies = df.loc[~df['time_of_purchase'].astype(str).str.match(pattern), 'time_of_purchase']\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"purchase_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Online', 'Station'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['purchase_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"payment_method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Contactless', 'Credit Card', 'Debit Card'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['payment_method'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"railcard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adult', 'None', 'Disabled', 'Senior'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['railcard'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['railcard'] = df['railcard'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"ticket_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Standard', 'First Class'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ticket_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"ticket_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Advance', 'Off-Peak', 'Anytime'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ticket_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        41,  42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "        55,  56,  57,  59,  63,  64,  65,  66,  67,  69,  70,  71,  72,\n",
       "        73,  74,  76,  77,  78,  80,  82,  84,  86,  88,  89,  90,  93,\n",
       "        94,  95,  96,  97, 101, 102, 104, 106, 107, 108, 109, 110, 111,\n",
       "       112, 113, 114, 116, 117, 118, 119, 121, 126, 128, 129, 134, 135,\n",
       "       143, 144, 146, 151, 154, 157, 158, 162, 168, 171, 176, 178, 180,\n",
       "       200, 203, 211, 216, 235, 238, 242, 267], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df['price'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"departure_station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['London Paddington', 'London Kings Cross', 'Liverpool Lime Street',\n",
       "       'London Euston', 'York', 'Manchester Piccadilly',\n",
       "       'Birmingham New Street', 'London St Pancras', 'Oxford', 'Reading',\n",
       "       'Edinburgh Waverley', 'Bristol Temple Meads'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['departure_station'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"arrival_station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Liverpool Lime Street', 'York', 'Manchester Piccadilly',\n",
       "       'Reading', 'London Euston', 'Oxford', 'Durham',\n",
       "       'London St Pancras', 'Birmingham New Street', 'London Paddington',\n",
       "       'Bristol Temple Meads', 'Tamworth', 'London Waterloo', 'Sheffield',\n",
       "       'Wolverhampton', 'Leeds', 'Stafford', 'Doncaster', 'Swindon',\n",
       "       'Nottingham', 'Peterborough', 'Edinburgh', 'Crewe',\n",
       "       'London Kings Cross', 'Leicester', 'Nuneaton', 'Didcot',\n",
       "       'Edinburgh Waverley', 'Coventry', 'Wakefield', 'Cardiff Central',\n",
       "       'Warrington'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arrival_station'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"date_of_journey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: date_of_journey, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "anomalies = df.loc[~df['date_of_journey'].astype(str).str.match(pattern), 'date_of_journey']\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"departure_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: departure_time, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^\\d{2}:\\d{2}:\\d{2}$'\n",
    "anomalies = df.loc[~df['departure_time'].astype(str).str.match(pattern), 'departure_time']\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"arrival_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: arrival_time, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^\\d{2}:\\d{2}:\\d{2}$'\n",
    "anomalies = df.loc[~df['arrival_time'].astype(str).str.match(pattern), 'arrival_time']\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"actual_arrival_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: actual_arrival_time, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^\\d{2}:\\d{2}:\\d{2}$'\n",
    "anomalies = df.loc[~df['actual_arrival_time'].astype(str).str.match(pattern).notna(), 'actual_arrival_time']\n",
    "print(anomalies)\n",
    "\n",
    "# The nulls in the column \"actual_arrival_time\" represent the cancelled journeys in the column \"journey_status\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"journey_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['On Time', 'Delayed', 'Cancelled'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['journey_status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"reason_for_delay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'Signal Failure', 'Technical Issue', 'Weather Conditions',\n",
       "       'Weather', 'Staffing', 'Staff Shortage', 'Signal failure',\n",
       "       'Traffic'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reason_for_delay'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reason_for_delay'] = df['reason_for_delay'].replace({'Signal failure': 'Signal Failure',\n",
    "                                                         'Weather': 'Weather Conditions',\n",
    "                                                         'Staffing': 'Staffing Issues',\n",
    "                                                         'Staff Shortage': 'Staffing Issues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reason_for_delay'] = df['reason_for_delay'].fillna('No Delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"refund_request\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['refund_request'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Transformed Data into SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the transformed \"railway\" data into the silver layer in the data warehouse\n",
    "\n",
    "server = 'mohamedibrahim'\n",
    "database = 'railway_dwh'\n",
    "\n",
    "connection_string = (\n",
    "    f'mssql+pyodbc://mohamedibrahim/railway_dwh'\n",
    "    '?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    '&Trusted_Connection=yes'\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "df.to_sql(\n",
    "    name='railway',\n",
    "    schema='silver',\n",
    "    con=engine,   \n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
