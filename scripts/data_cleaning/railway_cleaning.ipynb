{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate, Clean and Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the source data from the bronze layer in the data warehouse\n",
    "server = 'mohamedibrahim'\n",
    "database = 'railway_dwh'\n",
    "\n",
    "connection_string = (\n",
    "    f'mssql+pyodbc://mohamedibrahim/railway_dwh'\n",
    "    '?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    '&Trusted_Connection=yes'\n",
    ")\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = \"SELECT * FROM bronze.railway\"\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>Date_of_Purchase</th>\n",
       "      <th>Time_of_Purchase</th>\n",
       "      <th>Purchase_Type</th>\n",
       "      <th>Payment_Method</th>\n",
       "      <th>Railcard</th>\n",
       "      <th>Ticket_Class</th>\n",
       "      <th>Ticket_Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Departure_Station</th>\n",
       "      <th>Arrival_Station</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Departure_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Actual_Arrival_Time</th>\n",
       "      <th>Journey_Status</th>\n",
       "      <th>Reason_for_Delay</th>\n",
       "      <th>Refund_Request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>da8a6ba8-b3dc-4677-b176</td>\n",
       "      <td>2023-12-08</td>\n",
       "      <td>12:41:11</td>\n",
       "      <td>Online</td>\n",
       "      <td>Contactless</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>43</td>\n",
       "      <td>London Paddington</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b0cdd1b0-f214-4197-be53</td>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>11:23:01</td>\n",
       "      <td>Station</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>23</td>\n",
       "      <td>London Kings Cross</td>\n",
       "      <td>York</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>09:45:00</td>\n",
       "      <td>11:35:00</td>\n",
       "      <td>11:40:00</td>\n",
       "      <td>Delayed</td>\n",
       "      <td>Signal Failure</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f3ba7a96-f713-40d9-9629</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>19:51:27</td>\n",
       "      <td>Online</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>3</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>Manchester Piccadilly</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>18:15:00</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>18:45:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2471f11-4fe7-4c87-8ab4</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>23:00:36</td>\n",
       "      <td>Station</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>13</td>\n",
       "      <td>London Paddington</td>\n",
       "      <td>Reading</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2be00b45-0762-485e-a7a3</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>18:22:56</td>\n",
       "      <td>Online</td>\n",
       "      <td>Contactless</td>\n",
       "      <td>None</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Advance</td>\n",
       "      <td>76</td>\n",
       "      <td>Liverpool Lime Street</td>\n",
       "      <td>London Euston</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>16:45:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TransactionID Date_of_Purchase Time_of_Purchase Purchase_Type  \\\n",
       "0  da8a6ba8-b3dc-4677-b176       2023-12-08         12:41:11        Online   \n",
       "1  b0cdd1b0-f214-4197-be53       2023-12-16         11:23:01       Station   \n",
       "2  f3ba7a96-f713-40d9-9629       2023-12-19         19:51:27        Online   \n",
       "3  b2471f11-4fe7-4c87-8ab4       2023-12-20         23:00:36       Station   \n",
       "4  2be00b45-0762-485e-a7a3       2023-12-27         18:22:56        Online   \n",
       "\n",
       "  Payment_Method Railcard Ticket_Class Ticket_Type  Price  \\\n",
       "0    Contactless    Adult     Standard     Advance     43   \n",
       "1    Credit Card    Adult     Standard     Advance     23   \n",
       "2    Credit Card     None     Standard     Advance      3   \n",
       "3    Credit Card     None     Standard     Advance     13   \n",
       "4    Contactless     None     Standard     Advance     76   \n",
       "\n",
       "       Departure_Station        Arrival_Station Date_of_Journey  \\\n",
       "0      London Paddington  Liverpool Lime Street      2024-01-01   \n",
       "1     London Kings Cross                   York      2024-01-01   \n",
       "2  Liverpool Lime Street  Manchester Piccadilly      2024-01-02   \n",
       "3      London Paddington                Reading      2024-01-01   \n",
       "4  Liverpool Lime Street          London Euston      2024-01-01   \n",
       "\n",
       "  Departure_Time Arrival_Time Actual_Arrival_Time Journey_Status  \\\n",
       "0       11:00:00     13:30:00            13:30:00        On Time   \n",
       "1       09:45:00     11:35:00            11:40:00        Delayed   \n",
       "2       18:15:00     18:45:00            18:45:00        On Time   \n",
       "3       21:30:00     22:30:00            22:30:00        On Time   \n",
       "4       16:45:00     19:00:00            19:00:00        On Time   \n",
       "\n",
       "  Reason_for_Delay Refund_Request  \n",
       "0             None             No  \n",
       "1   Signal Failure             No  \n",
       "2             None             No  \n",
       "3             None             No  \n",
       "4             None             No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31653 entries, 0 to 31652\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   TransactionID        31653 non-null  object\n",
      " 1   Date_of_Purchase     31653 non-null  object\n",
      " 2   Time_of_Purchase     31653 non-null  object\n",
      " 3   Purchase_Type        31653 non-null  object\n",
      " 4   Payment_Method       31653 non-null  object\n",
      " 5   Railcard             31653 non-null  object\n",
      " 6   Ticket_Class         31653 non-null  object\n",
      " 7   Ticket_Type          31653 non-null  object\n",
      " 8   Price                31653 non-null  int64 \n",
      " 9   Departure_Station    31653 non-null  object\n",
      " 10  Arrival_Station      31653 non-null  object\n",
      " 11  Date_of_Journey      31653 non-null  object\n",
      " 12  Departure_Time       31653 non-null  object\n",
      " 13  Arrival_Time         31653 non-null  object\n",
      " 14  Actual_Arrival_Time  29773 non-null  object\n",
      " 15  Journey_Status       31653 non-null  object\n",
      " 16  Reason_for_Delay     4172 non-null   object\n",
      " 17  Refund_Request       31653 non-null  object\n",
      "dtypes: int64(1), object(17)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID              0\n",
       "Date_of_Purchase           0\n",
       "Time_of_Purchase           0\n",
       "Purchase_Type              0\n",
       "Payment_Method             0\n",
       "Railcard                   0\n",
       "Ticket_Class               0\n",
       "Ticket_Type                0\n",
       "Price                      0\n",
       "Departure_Station          0\n",
       "Arrival_Station            0\n",
       "Date_of_Journey            0\n",
       "Departure_Time             0\n",
       "Arrival_Time               0\n",
       "Actual_Arrival_Time     1880\n",
       "Journey_Status             0\n",
       "Reason_for_Delay       27481\n",
       "Refund_Request             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n",
      "It's all good :)\n"
     ]
    }
   ],
   "source": [
    "# Checks each object column for unwanted spaces (leading spaces, trailing spaces, multiple spaces)\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    has_unwanted_spaces = False\n",
    "    \n",
    "    # Iterate through non-null values and check each one\n",
    "    for value in df[col][df[col].notna()]:\n",
    "        # Convert to string and check for unwanted spaces\n",
    "        str_value = str(value)\n",
    "        # Check for leading/trailing spaces or multiple consecutive spaces\n",
    "        if str_value != str_value.strip() or '  ' in str_value:\n",
    "            has_unwanted_spaces = True\n",
    "            break\n",
    "    \n",
    "    if has_unwanted_spaces:\n",
    "        print(f\"Unwanted spaces found in column: {col}\")\n",
    "\n",
    "    else:\n",
    "        print(\"It's all good :)\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming Convention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section outlines the naming conventions used for tables, columns and other objects in the data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming Conventions: Use snake_case, with lowercase letters and underscores (_) to separate words, this applies to any tables, columns and objects exepect columns values, stays as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'transactionid': 'transaction_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"transaction_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transaction_id'].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"date_of_purchase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_of_purchase'] = pd.to_datetime(df['date_of_purchase'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_of_purchase'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>date_of_purchase</th>\n",
       "      <th>time_of_purchase</th>\n",
       "      <th>purchase_type</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>railcard</th>\n",
       "      <th>ticket_class</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>price</th>\n",
       "      <th>departure_station</th>\n",
       "      <th>arrival_station</th>\n",
       "      <th>date_of_journey</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>actual_arrival_time</th>\n",
       "      <th>journey_status</th>\n",
       "      <th>reason_for_delay</th>\n",
       "      <th>refund_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [transaction_id, date_of_purchase, time_of_purchase, purchase_type, payment_method, railcard, ticket_class, ticket_type, price, departure_station, arrival_station, date_of_journey, departure_time, arrival_time, actual_arrival_time, journey_status, reason_for_delay, refund_request]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for illogical purchase dates\n",
    "df.loc[df['date_of_purchase'] > df['date_of_journey']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"time_of_purchase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_of_purchase'] = pd.to_datetime(df['time_of_purchase'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time_of_purchase'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>date_of_purchase</th>\n",
       "      <th>time_of_purchase</th>\n",
       "      <th>purchase_type</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>railcard</th>\n",
       "      <th>ticket_class</th>\n",
       "      <th>ticket_type</th>\n",
       "      <th>price</th>\n",
       "      <th>departure_station</th>\n",
       "      <th>arrival_station</th>\n",
       "      <th>date_of_journey</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>actual_arrival_time</th>\n",
       "      <th>journey_status</th>\n",
       "      <th>reason_for_delay</th>\n",
       "      <th>refund_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [transaction_id, date_of_purchase, time_of_purchase, purchase_type, payment_method, railcard, ticket_class, ticket_type, price, departure_station, arrival_station, date_of_journey, departure_time, arrival_time, actual_arrival_time, journey_status, reason_for_delay, refund_request]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for illogical purchase time\n",
    "df.loc[(df['date_of_purchase'] == df['date_of_journey']) & (df['time_of_purchase'] > df['departure_time'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"purchase_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Online', 'Station'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['purchase_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"payment_method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Contactless', 'Credit Card', 'Debit Card'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['payment_method'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"railcard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adult', 'None', 'Disabled', 'Senior'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['railcard'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"ticket_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Standard', 'First Class'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ticket_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"ticket_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Advance', 'Off-Peak', 'Anytime'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ticket_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        41,  42,  43,  44,  45,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "        55,  56,  57,  59,  63,  64,  65,  66,  67,  69,  70,  71,  72,\n",
       "        73,  74,  76,  77,  78,  80,  82,  84,  86,  88,  89,  90,  93,\n",
       "        94,  95,  96,  97, 101, 102, 104, 106, 107, 108, 109, 110, 111,\n",
       "       112, 113, 114, 116, 117, 118, 119, 121, 126, 128, 129, 134, 135,\n",
       "       143, 144, 146, 151, 154, 157, 158, 162, 168, 171, 176, 178, 180,\n",
       "       200, 203, 211, 216, 235, 238, 242, 267])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(df['price'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"departure_station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['London Paddington', 'London Kings Cross', 'Liverpool Lime Street',\n",
       "       'London Euston', 'York', 'Manchester Piccadilly',\n",
       "       'Birmingham New Street', 'London St Pancras', 'Oxford', 'Reading',\n",
       "       'Edinburgh Waverley', 'Bristol Temple Meads'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['departure_station'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"arrival_station\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Liverpool Lime Street', 'York', 'Manchester Piccadilly',\n",
       "       'Reading', 'London Euston', 'Oxford', 'Durham',\n",
       "       'London St Pancras', 'Birmingham New Street', 'London Paddington',\n",
       "       'Bristol Temple Meads', 'Tamworth', 'London Waterloo', 'Sheffield',\n",
       "       'Wolverhampton', 'Leeds', 'Stafford', 'Doncaster', 'Swindon',\n",
       "       'Nottingham', 'Peterborough', 'Edinburgh', 'Crewe',\n",
       "       'London Kings Cross', 'Leicester', 'Nuneaton', 'Didcot',\n",
       "       'Edinburgh Waverley', 'Coventry', 'Wakefield', 'Cardiff Central',\n",
       "       'Warrington'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arrival_station'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"date_of_journey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_of_journey'] = pd.to_datetime(df['date_of_journey'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_of_journey'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"departure_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['departure_time'] = pd.to_datetime(df['departure_time'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['departure_time'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"arrival_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival_time'] = pd.to_datetime(df['arrival_time'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arrival_time'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"actual_arrival_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_arrival_time'] = pd.to_datetime(df['actual_arrival_time'], format='%H:%M:%S', errors='coerce').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1880)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['actual_arrival_time'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The nulls in the column \"actual_arrival_time\" represent the cancelled journeys in the column \"journey_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                transaction_id date_of_purchase time_of_purchase  \\\n",
      "39     69eaff73-ca3a-4831-905b       2024-01-01         03:52:29   \n",
      "75     a88f097f-bda3-4394-9c7d       2024-01-01         17:43:02   \n",
      "91     8a66ead7-e381-4311-b667       2024-01-02         00:54:33   \n",
      "111    d618c56f-3512-484d-9876       2024-01-02         03:33:32   \n",
      "148    eace2ada-5294-47e6-b4b8       2024-01-02         06:33:00   \n",
      "...                        ...              ...              ...   \n",
      "31639  465e3643-fb67-4deb-8ec9       2024-04-30         17:13:32   \n",
      "31641  2e96cde6-50c1-4311-8089       2024-04-30         17:16:04   \n",
      "31642  09e207d9-db49-4ec0-9c4f       2024-04-30         17:21:14   \n",
      "31644  1eacd955-f539-4c79-adb6       2024-04-30         17:26:33   \n",
      "31645  a0e238b7-1ad1-4bf7-bd6c       2024-04-30         18:11:50   \n",
      "\n",
      "      purchase_type payment_method  railcard ticket_class ticket_type  price  \\\n",
      "39           Online    Credit Card      None     Standard     Advance      7   \n",
      "75          Station     Debit Card  Disabled  First Class     Advance     35   \n",
      "91           Online    Credit Card      None     Standard    Off-Peak     10   \n",
      "111         Station    Credit Card      None     Standard    Off-Peak     12   \n",
      "148         Station    Credit Card      None  First Class     Anytime    235   \n",
      "...             ...            ...       ...          ...         ...    ...   \n",
      "31639       Station     Debit Card    Senior  First Class     Anytime    144   \n",
      "31641       Station    Credit Card     Adult     Standard     Anytime     95   \n",
      "31642        Online    Contactless      None     Standard     Anytime      5   \n",
      "31644        Online    Credit Card      None     Standard     Anytime     16   \n",
      "31645        Online    Credit Card    Senior  First Class     Anytime     13   \n",
      "\n",
      "           departure_station        arrival_station date_of_journey  \\\n",
      "39             London Euston  Birmingham New Street      2024-01-02   \n",
      "75             London Euston  Birmingham New Street      2024-01-02   \n",
      "91             London Euston  Birmingham New Street      2024-01-02   \n",
      "111        London St Pancras  Birmingham New Street      2024-01-02   \n",
      "148    Liverpool Lime Street          London Euston      2024-01-02   \n",
      "...                      ...                    ...             ...   \n",
      "31639          London Euston  Manchester Piccadilly      2024-04-30   \n",
      "31641          London Euston  Manchester Piccadilly      2024-04-30   \n",
      "31642  Manchester Piccadilly  Liverpool Lime Street      2024-04-30   \n",
      "31644      London St Pancras  Birmingham New Street      2024-04-30   \n",
      "31645  Manchester Piccadilly  Liverpool Lime Street      2024-04-30   \n",
      "\n",
      "      departure_time arrival_time actual_arrival_time journey_status  \\\n",
      "39          02:15:00     03:35:00                 NaT      Cancelled   \n",
      "75          16:00:00     17:20:00                 NaT      Cancelled   \n",
      "91          02:15:00     03:35:00                 NaT      Cancelled   \n",
      "111         05:00:00     06:20:00                 NaT      Cancelled   \n",
      "148         08:00:00     10:15:00                 NaT      Cancelled   \n",
      "...              ...          ...                 ...            ...   \n",
      "31639       18:45:00     20:35:00                 NaT      Cancelled   \n",
      "31641       18:45:00     20:35:00                 NaT      Cancelled   \n",
      "31642       18:45:00     19:15:00                 NaT      Cancelled   \n",
      "31644       18:45:00     20:05:00                 NaT      Cancelled   \n",
      "31645       18:45:00     19:15:00                 NaT      Cancelled   \n",
      "\n",
      "         reason_for_delay refund_request  \n",
      "39        Technical Issue             No  \n",
      "75        Technical Issue             No  \n",
      "91        Technical Issue            Yes  \n",
      "111              Staffing            Yes  \n",
      "148        Staff Shortage             No  \n",
      "...                   ...            ...  \n",
      "31639      Signal failure             No  \n",
      "31641      Signal failure            Yes  \n",
      "31642  Weather Conditions             No  \n",
      "31644      Signal Failure             No  \n",
      "31645  Weather Conditions             No  \n",
      "\n",
      "[1880 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "cancelled_journeys = df[(df['journey_status'] == 'Cancelled') & (df['actual_arrival_time'].isnull())]\n",
    "print(cancelled_journeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                transaction_id date_of_purchase time_of_purchase  \\\n",
      "10633  f10dc9f2-80c3-4b9f-8b72       2024-02-06         05:01:05   \n",
      "13933  add29bde-e183-426a-adca       2024-02-15         15:01:47   \n",
      "15130  3d6c240e-5c33-4665-9144       2024-02-21         11:54:54   \n",
      "16274  2b2bf794-2111-44bf-8758       2024-03-03         10:45:53   \n",
      "16483  bd082832-41f9-4364-a8d2       2024-03-04         07:46:54   \n",
      "16488  73bc8893-5e5f-47c6-951b       2024-03-04         07:56:08   \n",
      "16868  97203c12-be97-4199-8ac0       2024-03-05         16:11:29   \n",
      "16879  3d6779a3-1206-4b3b-872f       2024-03-05         17:07:35   \n",
      "18927  9fe75f16-a67a-4d45-9c92       2024-03-13         04:19:37   \n",
      "22975  9479bec9-2e01-4aac-be28       2024-03-28         05:09:54   \n",
      "23128  1923b77a-c469-41e7-98ea       2024-03-28         17:14:18   \n",
      "25003  c6a831e2-45a2-4089-8161       2024-04-06         02:01:10   \n",
      "25740  bfea5b54-7877-4ab1-9fed       2024-04-08         17:13:59   \n",
      "27923  441924c9-c008-4102-8b1d       2024-04-16         17:11:47   \n",
      "30495  cacaaff8-cede-4f77-9ae1       2024-04-26         06:05:42   \n",
      "30739  1f6f2747-3b49-40f4-a159       2024-04-27         04:58:52   \n",
      "30740  8a62b6cd-d298-420c-a4fa       2024-04-27         04:59:38   \n",
      "30866  67488422-ff65-46f9-b35b       2024-04-27         15:13:00   \n",
      "\n",
      "      purchase_type payment_method  railcard ticket_class ticket_type  price  \\\n",
      "10633       Station    Credit Card      None     Standard     Advance     84   \n",
      "13933       Station     Debit Card      None     Standard    Off-Peak     31   \n",
      "15130       Station     Debit Card     Adult  First Class     Advance     19   \n",
      "16274        Online     Debit Card     Adult     Standard     Advance      2   \n",
      "16483        Online     Debit Card    Senior     Standard    Off-Peak      3   \n",
      "16488        Online    Contactless    Senior     Standard    Off-Peak      3   \n",
      "16868       Station    Contactless     Adult     Standard     Anytime    101   \n",
      "16879       Station     Debit Card     Adult     Standard     Anytime    101   \n",
      "18927       Station     Debit Card    Senior     Standard    Off-Peak     76   \n",
      "22975       Station    Credit Card      None     Standard     Advance     84   \n",
      "23128       Station     Debit Card     Adult     Standard     Anytime    112   \n",
      "25003       Station    Credit Card      None     Standard    Off-Peak    126   \n",
      "25740       Station     Debit Card     Adult     Standard     Anytime    101   \n",
      "27923       Station     Debit Card     Adult     Standard     Anytime    112   \n",
      "30495        Online    Credit Card  Disabled     Standard     Anytime     14   \n",
      "30739       Station    Contactless      None     Standard    Off-Peak     53   \n",
      "30740        Online     Debit Card      None     Standard    Off-Peak     53   \n",
      "30866       Station     Debit Card      None     Standard    Off-Peak    126   \n",
      "\n",
      "           departure_station        arrival_station date_of_journey  \\\n",
      "10633  Manchester Piccadilly          London Euston      2024-02-29   \n",
      "13933  Birmingham New Street          London Euston      2024-02-15   \n",
      "15130  Birmingham New Street  Manchester Piccadilly      2024-02-27   \n",
      "16274  Manchester Piccadilly  Liverpool Lime Street      2024-03-04   \n",
      "16483  Manchester Piccadilly  Liverpool Lime Street      2024-03-04   \n",
      "16488  Manchester Piccadilly  Liverpool Lime Street      2024-03-04   \n",
      "16868  Liverpool Lime Street          London Euston      2024-03-05   \n",
      "16879  Liverpool Lime Street          London Euston      2024-03-05   \n",
      "18927  Liverpool Lime Street          London Euston      2024-03-13   \n",
      "22975  Manchester Piccadilly          London Euston      2024-03-29   \n",
      "23128  Manchester Piccadilly          London Euston      2024-03-28   \n",
      "25003  Manchester Piccadilly          London Euston      2024-04-06   \n",
      "25740  Liverpool Lime Street          London Euston      2024-04-08   \n",
      "27923  Manchester Piccadilly          London Euston      2024-04-16   \n",
      "30495                   York              Wakefield      2024-04-26   \n",
      "30739     London Kings Cross                   York      2024-04-27   \n",
      "30740     London Kings Cross                   York      2024-04-27   \n",
      "30866  Manchester Piccadilly          London Euston      2024-04-27   \n",
      "\n",
      "      departure_time arrival_time actual_arrival_time journey_status  \\\n",
      "10633       03:30:00     05:20:00            05:20:00        Delayed   \n",
      "13933       15:30:00     16:50:00            16:50:00        Delayed   \n",
      "15130       11:15:00     12:35:00            12:35:00        Delayed   \n",
      "16274       09:15:00     09:45:00            09:45:00        Delayed   \n",
      "16483       09:15:00     09:45:00            09:45:00        Delayed   \n",
      "16488       09:15:00     09:45:00            09:45:00        Delayed   \n",
      "16868       17:30:00     19:45:00            19:45:00        Delayed   \n",
      "16879       17:30:00     19:45:00            19:45:00        Delayed   \n",
      "18927       09:30:00     11:45:00            11:45:00        Delayed   \n",
      "22975       03:30:00     05:20:00            05:20:00        Delayed   \n",
      "23128       17:30:00     19:20:00            19:20:00        Delayed   \n",
      "25003       03:30:00     05:20:00            05:20:00        Delayed   \n",
      "25740       17:30:00     19:45:00            19:45:00        Delayed   \n",
      "27923       17:30:00     19:20:00            19:20:00        Delayed   \n",
      "30495       07:30:00     07:55:00            07:55:00        Delayed   \n",
      "30739       06:15:00     08:05:00            08:05:00        Delayed   \n",
      "30740       06:15:00     08:05:00            08:05:00        Delayed   \n",
      "30866       15:30:00     17:20:00            17:20:00        Delayed   \n",
      "\n",
      "         reason_for_delay refund_request  \n",
      "10633  Weather Conditions             No  \n",
      "13933            Staffing            Yes  \n",
      "15130     Technical Issue            Yes  \n",
      "16274             Weather             No  \n",
      "16483             Weather             No  \n",
      "16488             Weather             No  \n",
      "16868     Technical Issue             No  \n",
      "16879     Technical Issue            Yes  \n",
      "18927             Traffic            Yes  \n",
      "22975  Weather Conditions             No  \n",
      "23128     Technical Issue            Yes  \n",
      "25003  Weather Conditions             No  \n",
      "25740     Technical Issue            Yes  \n",
      "27923     Technical Issue            Yes  \n",
      "30495            Staffing             No  \n",
      "30739     Technical Issue             No  \n",
      "30740     Technical Issue             No  \n",
      "30866            Staffing            Yes  \n"
     ]
    }
   ],
   "source": [
    "# If the arrival time equals the actual arrival time then the journey status must be on time and the reason for delay must be no delay\n",
    "not_ontime_journeys = df[((df['arrival_time']) == (df['actual_arrival_time'])) & (df['journey_status'] != 'On Time')]\n",
    "print(not_ontime_journeys)\n",
    "# There is 18 rows that the journey status is delayed and there is reasons for delayes in this case, and that is not right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the journey_status and the reason_for_delay\n",
    "df.loc[((df['arrival_time']) == (df['actual_arrival_time'])) & (df['journey_status'] != 'On Time'), ['journey_status','reason_for_delay'] ] = ['On Time', 'No Delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"journey_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['On Time', 'Delayed', 'Cancelled'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['journey_status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"reason_for_delay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'Signal Failure', 'Technical Issue', 'Weather Conditions',\n",
       "       'Weather', 'Staffing', 'Staff Shortage', 'Signal failure',\n",
       "       'Traffic', 'No Delay'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reason_for_delay'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reason_for_delay'] = df['reason_for_delay'].replace({'Signal failure': 'Signal Failure',\n",
    "                                                         'Weather': 'Weather Conditions',\n",
    "                                                         'Staffing': 'Staffing Issues',\n",
    "                                                         'Staff Shortage': 'Staffing Issues'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reason_for_delay'] = df['reason_for_delay'].fillna('No Delay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column \"refund_request\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['refund_request'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Transformed Data into SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the transformed \"railway\" data into the silver layer in the data warehouse\n",
    "\n",
    "server = 'mohamedibrahim'\n",
    "database = 'railway_dwh'\n",
    "\n",
    "connection_string = (\n",
    "    f'mssql+pyodbc://mohamedibrahim/railway_dwh'\n",
    "    '?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    '&Trusted_Connection=yes'\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "df.to_sql(\n",
    "    name='railway',\n",
    "    schema='silver',\n",
    "    con=engine,   \n",
    "    if_exists='append',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
